<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Real-time Camera and TensorFlow.js</title>
    <style>
        #cameraCanvas {
            position: absolute;
            top: 0;
            left: 0;
        }
    </style>
</head>
<body>
    <canvas id="cameraCanvas" width="512" height="512"></canvas>

    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
    <script>
        let video;
        let cameraCanvas = document.getElementById('cameraCanvas');
        let cameraCtx = cameraCanvas.getContext('2d');

        let model;

        // Загрузка модели
        async function loadModel() {
            model = await tf.loadLayersModel('./jsModel/model.json');
            console.log("Модель загружена");
        }

        // Инициализация камеры
        async function setupCamera() {
            video = document.createElement('video');
            const stream = await navigator.mediaDevices.getUserMedia({
                video: { facingMode: { exact: "environment" } }
            });
            video.srcObject = stream;
            video.play();
            video.addEventListener('loadeddata', () => {
                processVideoFrame(); // Начинаем обработку
            });
        }

        // Обработка каждого кадра с камеры
        async function processVideoFrame() {
            // Отображаем изображение с камеры
            cameraCtx.drawImage(video, 0, 0, cameraCanvas.width, cameraCanvas.height);

            // Преобразование изображения в тензор
            let imageTensor = tf.browser.fromPixels(cameraCanvas, 3)
                                        .resizeBilinear([224, 224])
                                        .div(255.0)
                                        .expandDims();

            // Прогоняем через модель
            const predictions = await model.predict(imageTensor);

            // Получаем предсказанную маску (224x224, один канал, от 0 до 1)
            const unetMask = predictions;
            const unetMaskArray = unetMask.dataSync();

            // Создание изображения для маски
            const maskImageData = cameraCtx.createImageData(cameraCanvas.width, cameraCanvas.height);

            // Масштабирование маски до размера холста
            const scale = cameraCanvas.width / 224; // или cameraCanvas.height / 224, если соотношение сторон одинаковое
            for (let y = 0; y < 224; y++) {
                for (let x = 0; x < 224; x++) {
                    const value = unetMaskArray[y * 224 + x] * 255;  // Приведение значений к диапазону [0, 255]
                    #const destX = Math.floor(x * scale);
                    #const destY = Math.floor(y * scale);

                    // Корректное позиционирование пикселей
                    const index = (destY * cameraCanvas.width + destX) * 4;
                    maskImageData.data[index + 0] = value;       // R
                    maskImageData.data[index + 1] = value;         // G
                    maskImageData.data[index + 2] = value;         // B
                    maskImageData.data[index + 3] = value; // A (полупрозрачность)
                }
            }

            // Накладываем маску на изображение с камеры
            cameraCtx.putImageData(maskImageData, 0, 0);

            requestAnimationFrame(processVideoFrame); // Повторяем обработку
        }

        // Инициализация: загрузка модели и установка камеры
        loadModel().then(setupCamera);
    </script>
</body>
</html>
