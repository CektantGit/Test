<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Real-time Camera and TensorFlow.js</title>
    <style>
        #camera, #outputCanvas, #predictionCanvas {
            position: absolute;
            top: 0;
            left: 0;
        }
        #results {
            position: absolute;
            top: 10px;
            left: 10px;
            color: white;
            font-size: 18px;
        }
    </style>
</head>
<body>
    <video id="camera" autoplay playsinline></video>
    <canvas id="outputCanvas" width="512" height="512"></canvas>
    <canvas id="predictionCanvas" width="224" height="224"></canvas>

    <div id="results">
        <p id="position-result">Position: </p>
        <p id="orientation-result">Orientation: </p>
    </div>

    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
    <script>
        let video = document.getElementById('camera');
        let outputCanvas = document.getElementById('outputCanvas');
        let predictionCanvas = document.getElementById('predictionCanvas');
        let outputCtx = outputCanvas.getContext('2d');
        let predictionCtx = predictionCanvas.getContext('2d');

        let model;

        // Загрузка модели
        async function loadModel() {
            model = await tf.loadLayersModel('./jsModel/model.json');
            console.log("Модель загружена");
        }

        // Инициализация камеры
        async function setupCamera() {
            const stream = await navigator.mediaDevices.getUserMedia({
                video: { facingMode: { exact: "environment" } }
            });
            video.srcObject = stream;
            video.addEventListener('loadeddata', () => {
                processVideoFrame(); // Начинаем обработку
            });
        }

        // Обработка каждого кадра с камеры
        async function processVideoFrame() {
            outputCtx.drawImage(video, 0, 0, outputCanvas.width, outputCanvas.height);

            // Преобразование изображения в тензор
            let imageTensor = tf.browser.fromPixels(outputCanvas, 1)
                                        .resizeBilinear([224, 224])
                                        .div(255.0)
                                        .expandDims();

            // Прогоняем через модель
            const predictions = await model.predict(imageTensor);

            // Получаем предсказанную маску (224x224, один канал, от 0 до 1)
            const unetMask = predictions[0];
            const unetMaskArray = unetMask.dataSync();
            const imageData = predictionCtx.createImageData(224, 224);

            for (let i = 0; i < 224 * 224; i++) {
                const value = unetMaskArray[i] * 255;  // Масштабируем значения к [0, 255]
                imageData.data[i * 4] = value;         // R
                imageData.data[i * 4 + 1] = value;     // G
                imageData.data[i * 4 + 2] = value;     // B
                imageData.data[i * 4 + 3] = 255;       // A (прозрачность)
            }

            predictionCtx.putImageData(imageData, 0, 0);

            requestAnimationFrame(processVideoFrame); // Повторяем обработку
        }

        // Инициализация: загрузка модели и установка камеры
        loadModel().then(setupCamera);
    </script>
</body>
</html>
