<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>WebXR AR with Camera Access Fix</title>
  <script src="https://unpkg.com/three@0.122.0/build/three.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.7.0/dist/tf.min.js"></script>
  <style>
    body { margin: 0; overflow: hidden; }
    canvas { display: block; }
    #startARBtn, #captureButton, #maskImage {
      position: absolute;
      z-index: 12;
    }
    #startARBtn {
      top: 10px;
      left: 10px;
      padding: 10px;
      background: rgba(0,0,0,0.6);
      color: white;
      border: none;
      border-radius: 5px;
    }
    #captureButton {
      top: 60px;
      left: 10px;
      padding: 10px;
      background: rgba(0,0,0,0.6);
      color: white;
      border: none;
      border-radius: 5px;
    }
    #maskImage {
      top: 0;
      left: 0;
      width: 100%;
      height: 100%;
      object-fit: contain;
      pointer-events: none;
    }
  </style>
</head>
<body>
  <button id="startARBtn">Start AR</button>
  <button id="captureButton">Capture Image</button>
  <img id="maskImage"/>

  <script>
    let renderer, scene, camera, session, glBinding, resources;
    let model;
    let isProcessing = false;
    let runAutoLoop = false;
    let referenceSpace;

    const fragmentSource = `
      #extension GL_OES_EGL_image_external : require
      precision mediump float;
      varying vec2 vTexCoord;
      uniform samplerExternalOES uSampler;
      void main(void) {
        gl_FragColor = texture2D(uSampler, vTexCoord);
      }
    `;

    const vertexSource = `
      attribute vec4 aVertexPosition;
      attribute vec2 aTextureCoord;
      varying vec2 vTexCoord;
      void main(void) {
        gl_Position = aVertexPosition;
        vTexCoord = vec2(aTextureCoord.x, 1.0 - aTextureCoord.y);
      }
    `;

    async function loadModel() {
      model = await tf.loadLayersModel('jsModel/model.json');
    }

    function initWebGLResources(gl) {
      const vertexShader = createShader(gl, gl.VERTEX_SHADER, vertexSource);
      const fragmentShader = createShader(gl, gl.FRAGMENT_SHADER, fragmentSource);
      const program = createProgram(gl, vertexShader, fragmentShader);

      const texture = gl.createTexture();
      gl.bindTexture(gl.TEXTURE_EXTERNAL_OES, texture);
      gl.texParameteri(gl.TEXTURE_EXTERNAL_OES, gl.TEXTURE_MIN_FILTER, gl.LINEAR);
      gl.texParameteri(gl.TEXTURE_EXTERNAL_OES, gl.TEXTURE_MAG_FILTER, gl.LINEAR);
      gl.texParameteri(gl.TEXTURE_EXTERNAL_OES, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE);
      gl.texParameteri(gl.TEXTURE_EXTERNAL_OES, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE);

      const framebuffer = gl.createFramebuffer();
      const positionBuffer = gl.createBuffer();
      gl.bindBuffer(gl.ARRAY_BUFFER, positionBuffer);
      gl.bufferData(gl.ARRAY_BUFFER, new Float32Array([
        -1, -1, 0, 0,
         1, -1, 1, 0,
        -1,  1, 0, 1,
         1,  1, 1, 1
      ]), gl.STATIC_DRAW);

      return { program, texture, framebuffer, positionBuffer };
    }

    function createShader(gl, type, source) {
      const shader = gl.createShader(type);
      gl.shaderSource(shader, source);
      gl.compileShader(shader);
      if (!gl.getShaderParameter(shader, gl.COMPILE_STATUS)) {
        console.error(gl.getShaderInfoLog(shader));
        gl.deleteShader(shader);
        return null;
      }
      return shader;
    }

    function createProgram(gl, vs, fs) {
      const program = gl.createProgram();
      gl.attachShader(program, vs);
      gl.attachShader(program, fs);
      gl.linkProgram(program);
      if (!gl.getProgramParameter(program, gl.LINK_STATUS)) {
        console.error(gl.getProgramInfoLog(program));
        return null;
      }
      return program;
    }

    async function captureImage(gl, glBinding, view, resources) {
      const { program, texture, framebuffer, positionBuffer } = resources;
      const tex = glBinding.getCameraImage(view.camera);
      if (!tex) {
        console.warn("No texture from getCameraImage");
        return;
      }

      const width = gl.drawingBufferWidth;
      const height = gl.drawingBufferHeight;

      gl.bindFramebuffer(gl.FRAMEBUFFER, framebuffer);
      gl.framebufferTexture2D(gl.FRAMEBUFFER, gl.COLOR_ATTACHMENT0, gl.TEXTURE_EXTERNAL_OES, texture, 0);
      gl.useProgram(program);
      gl.viewport(0, 0, width, height);
      gl.activeTexture(gl.TEXTURE0);
      gl.bindTexture(gl.TEXTURE_EXTERNAL_OES, tex);
      gl.uniform1i(gl.getUniformLocation(program, 'uSampler'), 0);

      const pos = gl.getAttribLocation(program, 'aVertexPosition');
      const texCoord = gl.getAttribLocation(program, 'aTextureCoord');
      gl.bindBuffer(gl.ARRAY_BUFFER, positionBuffer);
      gl.enableVertexAttribArray(pos);
      gl.vertexAttribPointer(pos, 2, gl.FLOAT, false, 16, 0);
      gl.enableVertexAttribArray(texCoord);
      gl.vertexAttribPointer(texCoord, 2, gl.FLOAT, false, 16, 8);
      gl.drawArrays(gl.TRIANGLE_STRIP, 0, 4);

      const pixels = new Uint8Array(width * height * 4);
      gl.readPixels(0, 0, width, height, gl.RGBA, gl.UNSIGNED_BYTE, pixels);

      const imgTensor = tf.tensor3d(pixels, [height, width, 4], 'int32').slice([0, 0, 0], [-1, -1, 3]).div(255);
      const resized = tf.image.resizeBilinear(imgTensor, [224, 224]).expandDims();
      const prediction = await model.predict(resized);
      const data = prediction.dataSync();
      const out = new Uint8ClampedArray(224 * 224 * 4);

      for (let i = 0; i < 224 * 224; i++) {
        const v = data[i] * 255;
        out.set([v, v, v, 255], i * 4);
      }

      const maskCanvas = new OffscreenCanvas(224, 224);
      const ctx = maskCanvas.getContext('2d');
      ctx.putImageData(new ImageData(out, 224, 224), 0, 0);
      const blob = await maskCanvas.convertToBlob();
      document.getElementById('maskImage').src = URL.createObjectURL(blob);
    }

    async function activateXR() {
      const canvas = document.createElement('canvas');
      document.body.appendChild(canvas);
      const gl = canvas.getContext('webgl', { xrCompatible: true });

      session = await navigator.xr.requestSession('immersive-ar', {
        requiredFeatures: ['hit-test'],
        optionalFeatures: ['camera-access', 'dom-overlay'],
        domOverlay: { root: document.body }
      });

      glBinding = new XRWebGLBinding(session, gl);
      resources = initWebGLResources(gl);

      session.updateRenderState({ baseLayer: new XRWebGLLayer(session, gl) });
      referenceSpace = await session.requestReferenceSpace('local');

      renderer = new THREE.WebGLRenderer({ canvas, context: gl, alpha: true });
      renderer.autoClear = false;
      camera = new THREE.PerspectiveCamera();
      camera.matrixAutoUpdate = false;
      scene = new THREE.Scene();

      session.requestAnimationFrame(function onXRFrame(t, frame) {
        session.requestAnimationFrame(onXRFrame);

        const pose = frame.getViewerPose(referenceSpace);
        if (!pose) return;
        const view = pose.views[0];
        const viewport = session.renderState.baseLayer.getViewport(view);
        renderer.setSize(viewport.width, viewport.height);

        camera.matrix.fromArray(view.transform.matrix);
        camera.projectionMatrix.fromArray(view.projectionMatrix);
        camera.updateMatrixWorld(true);

        if (runAutoLoop && !isProcessing && view.camera) {
          isProcessing = true;
          captureImage(gl, glBinding, view, resources).then(() => {
            isProcessing = false;
          });
        }

        renderer.render(scene, camera);
      });
    }

    document.getElementById('startARBtn').onclick = async () => {
      await loadModel();
      await activateXR();
    };

    document.getElementById('captureButton').onclick = () => {
      if (!isProcessing) runAutoLoop = true;
    };
  </script>
</body>
</html>
