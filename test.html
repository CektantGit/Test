<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>AR Real-time Segmentation (WebGPU Optimized)</title>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-backend-webgpu"></script>
  <style>
    body { margin: 0; overflow: hidden; }
    #maskCanvas {
      position: fixed;
      top: 0; left: 0;
      width: 100vw;
      height: 100vh;
      z-index: 9999;
      pointer-events: none;
      transform: rotate(180deg) scaleX(-1);
    }
    #inputPreview {
      position: absolute;
      top: 10px;
      right: 10px;
      width: 112px;
      height: 112px;
      z-index: 10000;
      border: 1px solid white;
      pointer-events: none;
      transform: rotate(180deg) scaleX(-1);
    }
    #info {
      position: absolute;
      bottom: 10px;
      left: 10px;
      color: white;
      background: rgba(0,0,0,0.5);
      padding: 6px;
      font-family: monospace;
      font-size: 12px;
      z-index: 20;
      white-space: pre-wrap;
    }
    #startBtn {
      position: absolute;
      top: 10px;
      left: 10px;
      z-index: 15;
      padding: 10px;
      background: rgba(0,0,0,0.7);
      color: white;
      border: none;
      border-radius: 5px;
      cursor: pointer;
    }
  </style>
</head>
<body>
  <button id="startBtn">Start AR Segmentation</button>
  <canvas id="maskCanvas"></canvas>
  <canvas id="inputPreview" width="224" height="224"></canvas>
  <div id="info">Status: idle</div>

  <script>
    let model;
    let gl, session, glBinding;
    let cameraProgram, positionBuffer, texCoordBuffer;
    let posLoc, texLoc, samplerLoc;
    const maskCanvas = document.getElementById('maskCanvas');
    const maskCtx = maskCanvas.getContext('2d');
    const inputCanvas = document.getElementById('inputPreview');
    const inputCtx = inputCanvas.getContext('2d');
    let fpsHistory = [];

    const logElem = document.getElementById('info');
    const logLines = [];

    function log(msg) {
      logLines.push(msg);
      logElem.textContent = logLines.join('\n');
      console.log(msg);
    }

    window.addEventListener('error', e => {
      log(`Error: ${e.message}`);
    });

    window.addEventListener('unhandledrejection', e => {
      log(`Unhandled: ${e.reason}`);
    });

    function initCameraQuad(gl) {
      const vsSource = `attribute vec2 aPosition; attribute vec2 aTexCoord; varying vec2 vTexCoord; void main() { vTexCoord = aTexCoord; gl_Position = vec4(aPosition, 0.0, 1.0); }`;
      const fsSource = `#extension GL_OES_EGL_image_external : require\nprecision mediump float; varying vec2 vTexCoord; uniform samplerExternalOES uSampler; void main() { gl_FragColor = texture2D(uSampler, vTexCoord); }`;
      const vs = gl.createShader(gl.VERTEX_SHADER);
      gl.shaderSource(vs, vsSource);
      gl.compileShader(vs);
      const fs = gl.createShader(gl.FRAGMENT_SHADER);
      gl.shaderSource(fs, fsSource);
      gl.compileShader(fs);
      cameraProgram = gl.createProgram();
      gl.attachShader(cameraProgram, vs);
      gl.attachShader(cameraProgram, fs);
      gl.linkProgram(cameraProgram);
      posLoc = gl.getAttribLocation(cameraProgram, 'aPosition');
      texLoc = gl.getAttribLocation(cameraProgram, 'aTexCoord');
      samplerLoc = gl.getUniformLocation(cameraProgram, 'uSampler');
      positionBuffer = gl.createBuffer();
      gl.bindBuffer(gl.ARRAY_BUFFER, positionBuffer);
      gl.bufferData(gl.ARRAY_BUFFER, new Float32Array([-1, -1, 1, -1, -1, 1, 1, 1]), gl.STATIC_DRAW);
      texCoordBuffer = gl.createBuffer();
      gl.bindBuffer(gl.ARRAY_BUFFER, texCoordBuffer);
      gl.bufferData(gl.ARRAY_BUFFER, new Float32Array([0, 1, 1, 1, 0, 0, 1, 0]), gl.STATIC_DRAW);
      gl.getExtension('OES_EGL_image_external');
    }

    function drawCameraFrame(view) {
      const cameraTex = glBinding.getCameraImage(view.camera);
      if (!cameraTex) return false;
      gl.useProgram(cameraProgram);
      gl.activeTexture(gl.TEXTURE0);
      gl.bindTexture(gl.TEXTURE_EXTERNAL_OES, cameraTex);
      gl.uniform1i(samplerLoc, 0);
      gl.viewport(0, 0, gl.drawingBufferWidth, gl.drawingBufferHeight);
      gl.bindBuffer(gl.ARRAY_BUFFER, positionBuffer);
      gl.enableVertexAttribArray(posLoc);
      gl.vertexAttribPointer(posLoc, 2, gl.FLOAT, false, 0, 0);
      gl.bindBuffer(gl.ARRAY_BUFFER, texCoordBuffer);
      gl.enableVertexAttribArray(texLoc);
      gl.vertexAttribPointer(texLoc, 2, gl.FLOAT, false, 0, 0);
      gl.drawArrays(gl.TRIANGLE_STRIP, 0, 4);
      // Ensure the camera frame is fully rendered before it's read back.
      gl.finish();
      return true;
    }

    async function preprocess(source) {
      try {
        if (inputCanvas.width !== 224 || inputCanvas.height !== 224) {
          inputCanvas.width = inputCanvas.height = 224;
        }
        inputCtx.drawImage(source, 0, 0, 224, 224);
        return tf.tidy(() =>
          tf.browser
            .fromPixels(source, 3)
            .resizeBilinear([224, 224])
            .toFloat()
            .div(255)
            .expandDims(0)
        );
      } catch (e) {
        log('preprocess failed: ' + e.message);
        throw e;
      }
    }

    async function postprocess(maskTensor) {
      try {
        await tf.browser.toPixels(
          tf.tidy(() =>
            maskTensor
              .resizeBilinear([maskCanvas.height, maskCanvas.width])
              .mul(255)
              .toInt()
          ),
          maskCanvas
        );
      } catch (e) {
        log('postprocess failed: ' + e.message);
        throw e;
      }
    }

    async function loadModel() {
      try {
        await tf.setBackend('webgpu');
        await tf.ready();
        log('Using WebGPU backend');
      } catch (e) {
        log('WebGPU init failed, falling back to WebGL...');
        await tf.setBackend('webgl');
        await tf.ready();
        log('Using WebGL backend');
      }
      try {
        model = await tf.loadLayersModel('jsModel/model.json');
        log('Model loaded');
      } catch (e) {
        log('Model load failed: ' + e.message);
        throw e;
      }
    }

    async function startAR() {
      log('Starting AR...');
      try {
        await loadModel();
      } catch (e) {
        log('Initialization error: ' + e.message);
        return;
      }

      const canvas = document.createElement('canvas');
      canvas.width = 224;
      canvas.height = 224;
      document.body.appendChild(canvas);
      // Preserve the drawing buffer so createImageBitmap captures the
      // current camera frame instead of a cleared canvas.
      gl = canvas.getContext('webgl', {
        xrCompatible: true,
        preserveDrawingBuffer: true
      });

      try {
        session = await navigator.xr.requestSession('immersive-ar', {
          requiredFeatures: ['camera-access', 'dom-overlay'],
          domOverlay: { root: document.body }
        });
      } catch (e) {
        log('Failed to start AR session: ' + e.message);
        return;
      }

      session.updateRenderState({ baseLayer: new XRWebGLLayer(session, gl) });
      glBinding = new XRWebGLBinding(session, gl);
      initCameraQuad(gl);
      const referenceSpace = await session.requestReferenceSpace('local');

      let lastFrameTime = performance.now();

      async function onFrame(time, frame) {
        const pose = frame.getViewerPose(referenceSpace);
        if (!pose) {
          session.requestAnimationFrame(onFrame);
          return;
        }
        const view = pose.views[0];

        gl.bindFramebuffer(gl.FRAMEBUFFER, session.renderState.baseLayer.framebuffer);
        if (!drawCameraFrame(view)) {
          session.requestAnimationFrame(onFrame);
          return;
        }

        const tPreStart = performance.now();
        const input = await preprocess(gl.canvas);
        const meanVal = (await input.mean().data())[0];
        log('input mean ' + meanVal.toFixed(3));
        const tPreEnd = performance.now();

        const tPredictStart = performance.now();
        const mask = tf.tidy(() => {
          const pred = model.predict(input).squeeze();
          return pred.greater(0.5).toFloat();
        });
        await tf.nextFrame();
        const tPredictEnd = performance.now();

        if (
          maskCanvas.width !== window.innerWidth ||
          maskCanvas.height !== window.innerHeight
        ) {
          maskCanvas.width = window.innerWidth;
          maskCanvas.height = window.innerHeight;
        }

        const tPostStart = performance.now();
        await postprocess(mask);
        const tPostEnd = performance.now();
        tf.dispose([input, mask]);

        const now = performance.now();
        const frameTime = now - lastFrameTime;
        lastFrameTime = now;
        fpsHistory.push(1000 / frameTime);
        if (fpsHistory.length > 30) fpsHistory.shift();
        const avgFps = fpsHistory.reduce((a, b) => a + b, 0) / fpsHistory.length;

        log(
          `Pre: ${(tPreEnd - tPreStart).toFixed(1)}ms\nInfer: ${(tPredictEnd - tPredictStart).toFixed(1)}ms\nPost: ${(tPostEnd - tPredictEnd).toFixed(1)}ms\nFPS: ${avgFps.toFixed(1)}`
        );

        session.requestAnimationFrame(onFrame);
      }

      session.requestAnimationFrame(onFrame);

      document.getElementById('startBtn').style.display = 'none';
    }

    document.getElementById('startBtn').addEventListener('click', () => {
      startAR().catch(e => log('Unexpected error: ' + e.message));
    });
  </script>
</body>
</html>
