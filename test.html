<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>AR Capture</title>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.7.0/dist/tf.min.js"></script>
  <script src="https://unpkg.com/three@0.122.0/build/three.js"></script>
  <script src="https://unpkg.com/three@0.122.0/examples/js/loaders/GLTFLoader.js"></script>
  <script src="https://unpkg.com/three@0.122.0/examples/js/vr/ARButton.js"></script>
  <style>
    body { margin: 0; overflow: hidden; font-family: monospace; background: white; color: black; }
    canvas { display: block; }
    #info { position: absolute; bottom: 10px; left: 10px; white-space: pre-wrap; font-size: 12px; background: rgba(255,255,255,0.8); padding: 10px; z-index: 20; max-width: 90vw; }
    #captureButton, #startARBtn {
      position: absolute;
      top: 10px;
      left: 10px;
      z-index: 15;
      padding: 10px;
      background: rgba(0,0,0,0.7);
      color: white;
      border: none;
      border-radius: 5px;
      cursor: pointer;
    }
    #captureButton { top: 60px; }
    #maskCanvas {
      position: absolute;
      top: 0;
      left: 0;
      width: 100%;
      height: 100%;
      image-rendering: pixelated;
      z-index: 10;
      pointer-events: none;
    }
  </style>
</head>
<body>
  <button id="startARBtn">Start AR</button>
  <button id="captureButton">Capture Image</button>
  <div id="info">Log:</div>
  <canvas id="maskCanvas" width="224" height="224"></canvas>

  <script>
    let model, renderer, camera, scene, gl, session, glBinding;
    let running = false;
    let processing = false;
    let referenceSpace;

    let maskCtx = document.getElementById('maskCanvas').getContext('2d');

    async function loadModel() {
      model = await tf.loadLayersModel('jsModel/model.json');
      log("Model loaded.");
    }

    function log(msg) {
      document.getElementById('info').textContent = "Log:\n" + msg;
    }

    async function startAR() {
      await loadModel();
      const canvas = document.createElement('canvas');
      document.body.appendChild(canvas);
      gl = canvas.getContext('webgl', { xrCompatible: true });

      session = await navigator.xr.requestSession('immersive-ar', {
        requiredFeatures: ['hit-test', 'dom-overlay', 'camera-access'],
        domOverlay: { root: document.body }
      });

      session.updateRenderState({ baseLayer: new XRWebGLLayer(session, gl) });
      referenceSpace = await session.requestReferenceSpace('local');
      glBinding = new XRWebGLBinding(session, gl);

      renderer = new THREE.WebGLRenderer({ canvas: canvas, context: gl, alpha: true });
      renderer.autoClear = false;
      camera = new THREE.PerspectiveCamera();
      camera.matrixAutoUpdate = false;
      scene = new THREE.Scene();

      session.requestAnimationFrame(onXRFrame);
      document.getElementById('startARBtn').style.display = 'none';
    }

    async function processCameraFrame(view) {
      if (processing) return;
      processing = true;
      try {
        const baseLayer = session.renderState.baseLayer;
        const width = baseLayer.framebufferWidth;
        const height = baseLayer.framebufferHeight;

        const pixels = new Uint8Array(width * height * 4);
        gl.readPixels(0, 0, width, height, gl.RGBA, gl.UNSIGNED_BYTE, pixels);

        const canvas = document.createElement('canvas');
        canvas.width = width;
        canvas.height = height;
        const ctx = canvas.getContext('2d');

        const imageData = ctx.createImageData(width, height);
        imageData.data.set(pixels);
        ctx.putImageData(imageData, 0, 0);

        const input = tf.browser.fromPixels(canvas, 3).div(255);
        const resized = tf.image.resizeBilinear(input, [224, 224]).expandDims();
        const pred = await model.predict(resized);
        const arr = await pred.data();

        const output = maskCtx.createImageData(224, 224);
        for (let i = 0; i < 224 * 224; i++) {
          const v = arr[i] * 255;
          output.data[i * 4] = v;
          output.data[i * 4 + 1] = v;
          output.data[i * 4 + 2] = v;
          output.data[i * 4 + 3] = 255;
        }
        maskCtx.putImageData(output, 0, 0);
      } catch (e) {
        log("Error: " + e.message);
      } finally {
        processing = false;
      }
    }

    function onXRFrame(time, frame) {
      session.requestAnimationFrame(onXRFrame);
      const pose = frame.getViewerPose(referenceSpace);
      if (!pose) return;
      const view = pose.views[0];

      const baseLayer = session.renderState.baseLayer;
      gl.bindFramebuffer(gl.FRAMEBUFFER, baseLayer.framebuffer);
      const viewport = baseLayer.getViewport(view);
      renderer.setSize(viewport.width, viewport.height);

      camera.matrix.fromArray(view.transform.matrix);
      camera.projectionMatrix.fromArray(view.projectionMatrix);
      camera.updateMatrixWorld(true);

      renderer.render(scene, camera);

      if (running && !processing) {
        processCameraFrame(view);
      }
    }

    document.getElementById('startARBtn').addEventListener('click', startAR);
    document.getElementById('captureButton').addEventListener('click', () => {
      running = true;
      log("Capture started.");
    });
  </script>
</body>
</html>
