<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>AR with WebXR</title>
  <script src="https://unpkg.com/three@0.122.0/build/three.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.7.0/dist/tf.min.js"></script>
  <style>
    body { margin: 0; overflow: hidden; }
    canvas { display: block; }
    #startARBtn, #captureButton {
      position: absolute;
      z-index: 12;
      background: rgba(0, 0, 0, 0.7);
      color: white;
      padding: 10px;
      border: none;
      border-radius: 5px;
      cursor: pointer;
    }
    #startARBtn { top: 10px; left: 10px; }
    #captureButton { top: 50px; left: 10px; }
    #maskImage {
      display: block;
      position: absolute;
      top: 0;
      left: 0;
      width: 100%;
      height: 100%;
      z-index: 10;
      object-fit: contain;
    }
    #info {
      position: absolute;
      bottom: 10px;
      left: 10px;
      color: white;
      background: rgba(0, 0, 0, 0.7);
      padding: 8px;
      z-index: 20;
      max-width: 90%;
      font-family: monospace;
      font-size: 14px;
      white-space: pre-wrap;
    }
  </style>
</head>
<body>
  <button id="startARBtn">Start AR</button>
  <button id="captureButton">Capture Image</button>
  <img id="maskImage"/>
  <div id="info">Log:</div>

<script>
let camera, scene, renderer, session, glBinding;
let model, captureNext = false, resources;

function log(msg) {
  document.getElementById('info').innerText += '\n' + msg;
}

async function loadModel() {
  try {
    model = await tf.loadLayersModel('jsModel/model.json');
    log('Model loaded.');
  } catch (err) {
    log('Model load error: ' + err.message);
  }
}

async function activateXR() {
  const canvas = document.createElement('canvas');
  document.body.appendChild(canvas);
  const gl = canvas.getContext('webgl', { xrCompatible: true });

  try {
    session = await navigator.xr.requestSession('immersive-ar', {
      requiredFeatures: ['hit-test', 'dom-overlay', 'camera-access'],
      domOverlay: { root: document.body }
    });
  } catch (err) {
    log('XR Session error: ' + err.message);
    return;
  }

  session.updateRenderState({ baseLayer: new XRWebGLLayer(session, gl) });
  glBinding = new XRWebGLBinding(session, gl);
  resources = initWebGLResources(gl);
  const referenceSpace = await session.requestReferenceSpace('local');

  renderer = new THREE.WebGLRenderer({ canvas, context: gl, alpha: true });
  renderer.autoClear = false;
  camera = new THREE.PerspectiveCamera();
  camera.matrixAutoUpdate = false;
  scene = new THREE.Scene();

  const onXRFrame = async (time, frame) => {
    session.requestAnimationFrame(onXRFrame);
    gl.bindFramebuffer(gl.FRAMEBUFFER, session.renderState.baseLayer.framebuffer);

    const pose = frame.getViewerPose(referenceSpace);
    if (!pose) return;
    const view = pose.views[0];
    const viewport = session.renderState.baseLayer.getViewport(view);
    renderer.setSize(viewport.width, viewport.height);
    camera.matrix.fromArray(view.transform.matrix);
    camera.projectionMatrix.fromArray(view.projectionMatrix);
    camera.updateMatrixWorld(true);

    if (captureNext) {
      captureNext = false;
      try {
        await captureImage(gl, glBinding, view.camera, resources);
      } catch (err) {
        log('Capture error: ' + err.message);
      }
    }

    renderer.render(scene, camera);
  };

  session.requestAnimationFrame(onXRFrame);
  document.getElementById('startARBtn').style.display = 'none';
}

function getShader(gl, src, type) {
  const shader = gl.createShader(type === 'fragment' ? gl.FRAGMENT_SHADER : gl.VERTEX_SHADER);
  gl.shaderSource(shader, src);
  gl.compileShader(shader);
  if (!gl.getShaderParameter(shader, gl.COMPILE_STATUS)) {
    log('Shader error: ' + gl.getShaderInfoLog(shader));
    return null;
  }
  return shader;
}

function getProgram(gl, vs, fs) {
  const vert = getShader(gl, vs, 'vertex');
  const frag = getShader(gl, fs, 'fragment');
  const prog = gl.createProgram();
  gl.attachShader(prog, vert);
  gl.attachShader(prog, frag);
  gl.linkProgram(prog);
  if (!gl.getProgramParameter(prog, gl.LINK_STATUS)) {
    log('Program error: ' + gl.getProgramInfoLog(prog));
    return null;
  }
  return prog;
}

function initWebGLResources(gl) {
  const vertexSource = `
    attribute vec4 aVertexPosition;
    attribute vec2 aTextureCoord;
    varying vec2 vTexCoord;
    void main(void) {
      gl_Position = aVertexPosition;
      vTexCoord = aTextureCoord;
    }
  `;
  const fragmentSource = `
    #extension GL_OES_EGL_image_external : require
    precision mediump float;
    varying vec2 vTexCoord;
    uniform samplerExternalOES uSampler;
    void main(void) {
      gl_FragColor = texture2D(uSampler, vTexCoord);
    }
  `;
  const program = getProgram(gl, vertexSource, fragmentSource);
  const texture = gl.createTexture();
  gl.bindTexture(gl.TEXTURE_EXTERNAL_OES, texture);
  gl.texParameteri(gl.TEXTURE_EXTERNAL_OES, gl.TEXTURE_MIN_FILTER, gl.LINEAR);
  gl.texParameteri(gl.TEXTURE_EXTERNAL_OES, gl.TEXTURE_MAG_FILTER, gl.LINEAR);
  gl.texParameteri(gl.TEXTURE_EXTERNAL_OES, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE);
  gl.texParameteri(gl.TEXTURE_EXTERNAL_OES, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE);
  const fb = gl.createFramebuffer();
  gl.bindFramebuffer(gl.FRAMEBUFFER, fb);
  return { program, texture, framebuffer: fb };
}

async function captureImage(gl, glBinding, dcamera, { program, texture, framebuffer }) {
  const img = glBinding.getCameraImage(dcamera);
  const width = dcamera.width;
  const height = dcamera.height;
  if (!img) throw new Error('getCameraImage returned null');

  gl.bindFramebuffer(gl.FRAMEBUFFER, framebuffer);
  gl.useProgram(program);
  gl.activeTexture(gl.TEXTURE0);
  gl.bindTexture(gl.TEXTURE_EXTERNAL_OES, img);
  gl.uniform1i(gl.getUniformLocation(program, 'uSampler'), 0);

  const verts = new Float32Array([
    -1, -1, 0, 0,
     1, -1, 1, 0,
    -1,  1, 0, 1,
     1,  1, 1, 1,
  ]);

  const buf = gl.createBuffer();
  gl.bindBuffer(gl.ARRAY_BUFFER, buf);
  gl.bufferData(gl.ARRAY_BUFFER, verts, gl.STATIC_DRAW);

  const pos = gl.getAttribLocation(program, 'aVertexPosition');
  const tex = gl.getAttribLocation(program, 'aTextureCoord');
  gl.enableVertexAttribArray(pos);
  gl.vertexAttribPointer(pos, 2, gl.FLOAT, false, 16, 0);
  gl.enableVertexAttribArray(tex);
  gl.vertexAttribPointer(tex, 2, gl.FLOAT, false, 16, 8);

  gl.viewport(0, 0, width, height);
  gl.drawArrays(gl.TRIANGLE_STRIP, 0, 4);

  const pixels = new Uint8Array(width * height * 4);
  gl.readPixels(0, 0, width, height, gl.RGBA, gl.UNSIGNED_BYTE, pixels);
  const flipped = new Uint8ClampedArray(pixels.length);
  for (let y = 0; y < height; y++) {
    for (let x = 0; x < width; x++) {
      const si = (y * width + x) * 4;
      const di = ((height - 1 - y) * width + x) * 4;
      flipped.set(pixels.slice(si, si + 4), di);
    }
  }

  const cvs = document.createElement('canvas');
  cvs.width = width;
  cvs.height = height;
  const ctx = cvs.getContext('2d');
  ctx.putImageData(new ImageData(flipped, width, height), 0, 0);

  const tensor = tf.browser.fromPixels(cvs).div(255.0).resizeBilinear([224, 224]).expandDims();
  const pred = await model.predict(tensor);
  const data = pred.dataSync();

  const mask = document.getElementById('maskImage');
  const out = document.createElement('canvas');
  out.width = 224;
  out.height = 224;
  const mctx = out.getContext('2d');
  const imgData = mctx.createImageData(224, 224);
  for (let i = 0; i < 224 * 224; i++) {
    const v = data[i] * 255;
    imgData.data[i * 4] = v;
    imgData.data[i * 4 + 1] = v;
    imgData.data[i * 4 + 2] = v;
    imgData.data[i * 4 + 3] = 255;
  }
  mctx.putImageData(imgData, 0, 0);
  mask.src = out.toDataURL();
  log('Segmentation completed.');
}

// === Entry point ===
document.getElementById('startARBtn').addEventListener('click', async () => {
  await loadModel();
  await activateXR();
});
document.getElementById('captureButton').addEventListener('click', () => captureNext = true);
</script>
</body>
</html>
