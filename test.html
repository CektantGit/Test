<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>AR Real-time Segmentation (WebGPU Optimized)</title>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-backend-webgpu"></script>
  <style>
    body { margin: 0; overflow: hidden; }
    #maskCanvas {
      position: fixed;
      top: 0; left: 0;
      width: 100vw;
      height: 100vh;
      z-index: 9999;
      pointer-events: none;
      transform: rotate(180deg) scaleX(-1);
    }
    #info {
      position: absolute;
      bottom: 10px;
      left: 10px;
      color: white;
      background: rgba(0,0,0,0.5);
      padding: 6px;
      font-family: monospace;
      font-size: 12px;
      z-index: 20;
      white-space: pre-wrap;
    }
    #startBtn {
      position: absolute;
      top: 10px;
      left: 10px;
      z-index: 15;
      padding: 10px;
      background: rgba(0,0,0,0.7);
      color: white;
      border: none;
      border-radius: 5px;
      cursor: pointer;
    }
  </style>
</head>
<body>
  <button id="startBtn">Start AR Segmentation</button>
  <canvas id="maskCanvas"></canvas>
  <div id="info">Status: idle</div>

  <script>
    let model;
    let gl, session;
    const maskCanvas = document.getElementById('maskCanvas');
    const maskCtx = maskCanvas.getContext('2d');
    let fpsHistory = [];

    const logElem = document.getElementById('info');
    const logLines = [];

    function log(msg) {
      logLines.push(msg);
      logElem.textContent = logLines.join('\n');
      console.log(msg);
    }

    window.addEventListener('error', e => {
      log(`Error: ${e.message}`);
    });

    window.addEventListener('unhandledrejection', e => {
      log(`Unhandled: ${e.reason}`);
    });

    // WebGPU resources for fully GPU-based pre/post processing
    const PREPROCESS_WGSL = `
      @group(0) @binding(0) var cameraTex : texture_2d<f32>;
      @group(0) @binding(1) var<storage, read_write> outBuf : array<f32>;
      @group(0) @binding(2) var samp : sampler;

      @compute @workgroup_size(8,8)
      fn main(@builtin(global_invocation_id) gid : vec3<u32>) {
        if (gid.x >= 224u || gid.y >= 224u) { return; }
        let uv = (vec2<f32>(gid.xy) + vec2<f32>(0.5)) / vec2<f32>(224.0, 224.0);
        let rgb = textureSampleLevel(cameraTex, samp, uv, 0.0).rgb;
        let idx = (gid.y * 224u + gid.x) * 3u;
        outBuf[idx+0u] = rgb.r;
        outBuf[idx+1u] = rgb.g;
        outBuf[idx+2u] = rgb.b;
      }
    `;

    const POSTPROCESS_WGSL = `
      @group(0) @binding(0) var<storage, read> mask : array<f32>;
      @group(0) @binding(1) var outTex : texture_storage_2d<rgba8unorm, write>;

      @compute @workgroup_size(8,8)
      fn main(@builtin(global_invocation_id) gid : vec3<u32>) {
        if (gid.x >= 224u || gid.y >= 224u) { return; }
        let m = mask[gid.y * 224u + gid.x];
        let color = vec4<f32>(1.0, 0.0, 0.0, m);
        textureStore(outTex, vec2<i32>(gid.xy), color);
      }
    `;

    let device, queue, preprocessPipeline, postprocessPipeline;
    let preprocessBuffer, preprocessReadback, postprocessTexture, sampler, cameraTexture;

    async function initGPU() {
      try {
        const adapter = await navigator.gpu.requestAdapter();
        device = await adapter.requestDevice();
        queue = device.queue;

        preprocessPipeline = device.createComputePipeline({
          layout: 'auto',
          compute: {
            module: device.createShaderModule({ code: PREPROCESS_WGSL }),
            entryPoint: 'main'
          }
        });

        postprocessPipeline = device.createComputePipeline({
          layout: 'auto',
          compute: {
            module: device.createShaderModule({ code: POSTPROCESS_WGSL }),
            entryPoint: 'main'
          }
        });

        preprocessBuffer = device.createBuffer({
          size: 224 * 224 * 3 * 4,
          usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_SRC
        });

        preprocessReadback = device.createBuffer({
          size: 224 * 224 * 3 * 4,
          usage: GPUBufferUsage.COPY_DST | GPUBufferUsage.MAP_READ
        });

        postprocessTexture = device.createTexture({
          size: [224, 224],
          format: 'rgba8unorm',
          usage: GPUTextureUsage.STORAGE_BINDING | GPUTextureUsage.TEXTURE_BINDING | GPUTextureUsage.COPY_SRC
        });

        sampler = device.createSampler({ magFilter: 'linear', minFilter: 'linear' });

        cameraTexture = device.createTexture({
          size: [224, 224],
          format: 'rgba8unorm',
          usage: GPUTextureUsage.TEXTURE_BINDING | GPUTextureUsage.COPY_DST
        });
      } catch (e) {
        log('initGPU failed: ' + e.message);
        throw e;
      }
    }

    async function preprocess(cameraBitmap) {
      try {
        queue.copyExternalImageToTexture(
          { source: cameraBitmap },
          { texture: cameraTexture },
          [224, 224]
        );
        const bind = device.createBindGroup({
          layout: preprocessPipeline.getBindGroupLayout(0),
          entries: [
            { binding: 0, resource: cameraTexture.createView() },
            { binding: 1, resource: { buffer: preprocessBuffer } },
            { binding: 2, resource: sampler }
          ]
        });
        const encoder = device.createCommandEncoder();
        const pass = encoder.beginComputePass();
        pass.setPipeline(preprocessPipeline);
        pass.setBindGroup(0, bind);
        pass.dispatchWorkgroups(Math.ceil(224 / 8), Math.ceil(224 / 8));
        pass.end();
        encoder.copyBufferToBuffer(
          preprocessBuffer,
          0,
          preprocessReadback,
          0,
          224 * 224 * 3 * 4
        );
        queue.submit([encoder.finish()]);
        await preprocessReadback.mapAsync(GPUMapMode.READ);
        const mapped = preprocessReadback.getMappedRange().slice(0);
        preprocessReadback.unmap();
        return tf.tensor(new Float32Array(mapped), [1, 224, 224, 3]);
      } catch (e) {
        log('preprocess failed: ' + e.message);
        throw e;
      }
    }

    async function postprocess(maskTensor) {
      try {
        const data = await maskTensor.data();
        const upload = device.createBuffer({
          size: data.byteLength,
          usage: GPUBufferUsage.COPY_SRC | GPUBufferUsage.MAP_WRITE,
          mappedAtCreation: true
        });
        new Float32Array(upload.getMappedRange()).set(data);
        upload.unmap();
        const maskBuf = device.createBuffer({
          size: data.byteLength,
          usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_DST
        });
        const encoder = device.createCommandEncoder();
        encoder.copyBufferToBuffer(upload, 0, maskBuf, 0, data.byteLength);
        const bind = device.createBindGroup({
          layout: postprocessPipeline.getBindGroupLayout(0),
          entries: [
            { binding: 0, resource: { buffer: maskBuf } },
            { binding: 1, resource: postprocessTexture.createView() }
          ]
        });
        const pass = encoder.beginComputePass();
        pass.setPipeline(postprocessPipeline);
        pass.setBindGroup(0, bind);
        pass.dispatchWorkgroups(Math.ceil(224 / 8), Math.ceil(224 / 8));
        pass.end();
        // Bytes per row in GPUBuffer copies must be a multiple of 256.
        // The 224 * 4 bytes produced per row (RGBA) need to be padded to meet
        // this requirement, otherwise WebGPU throws "offset is out of bounds".
        const bytesPerPixel = 4;
        const alignedBytesPerRow = Math.ceil((224 * bytesPerPixel) / 256) * 256;

        const readback = device.createBuffer({
          size: alignedBytesPerRow * 224,
          usage: GPUBufferUsage.COPY_DST | GPUBufferUsage.MAP_READ
        });
        encoder.copyTextureToBuffer(
          { texture: postprocessTexture },
          {
            buffer: readback,
            bytesPerRow: alignedBytesPerRow,
          },
          { width: 224, height: 224, depthOrArrayLayers: 1 }
        );
        queue.submit([encoder.finish()]);
        await readback.mapAsync(GPUMapMode.READ);
        const mapped = new Uint8Array(readback.getMappedRange());

        // Remove row padding before creating ImageData
        const array = new Uint8ClampedArray(224 * 224 * bytesPerPixel);
        for (let y = 0; y < 224; y++) {
          const srcOffset = y * alignedBytesPerRow;
          const dstOffset = y * 224 * bytesPerPixel;
          array.set(
            mapped.subarray(srcOffset, srcOffset + 224 * bytesPerPixel),
            dstOffset
          );
        }
        readback.unmap();
        const imageData = new ImageData(array, 224, 224);
        const off = document.createElement('canvas');
        off.width = 224;
        off.height = 224;
        off.getContext('2d').putImageData(imageData, 0, 0);
        maskCtx.clearRect(0, 0, maskCanvas.width, maskCanvas.height);
        maskCtx.drawImage(off, 0, 0, maskCanvas.width, maskCanvas.height);
      } catch (e) {
        log('postprocess failed: ' + e.message);
        throw e;
      }
    }

    async function loadModel() {
      try {
        await tf.setBackend('webgpu');
        await tf.ready();
        log('Using WebGPU backend');
      } catch (e) {
        log('WebGPU init failed, falling back to WebGL...');
        await tf.setBackend('webgl');
        await tf.ready();
        log('Using WebGL backend');
      }
      try {
        model = await tf.loadLayersModel('jsModel/model.json');
        log('Model loaded');
      } catch (e) {
        log('Model load failed: ' + e.message);
        throw e;
      }
    }

    async function startAR() {
      log('Starting AR...');
      try {
        await loadModel();
        await initGPU();
      } catch (e) {
        log('Initialization error: ' + e.message);
        return;
      }

      const canvas = document.createElement('canvas');
      canvas.width = 224;
      canvas.height = 224;
      document.body.appendChild(canvas);
      gl = canvas.getContext('webgl', { xrCompatible: true });

      try {
        session = await navigator.xr.requestSession('immersive-ar', {
          requiredFeatures: ['camera-access', 'dom-overlay'],
          domOverlay: { root: document.body }
        });
      } catch (e) {
        log('Failed to start AR session: ' + e.message);
        return;
      }

      session.updateRenderState({ baseLayer: new XRWebGLLayer(session, gl) });
      const referenceSpace = await session.requestReferenceSpace('local');

      let lastFrameTime = performance.now();

      async function onFrame(time, frame) {
        const pose = frame.getViewerPose(referenceSpace);
        if (!pose) {
          session.requestAnimationFrame(onFrame);
          return;
        }

        let tex;
        try {
          tex = await createImageBitmap(gl.canvas);
        } catch (_) {
          session.requestAnimationFrame(onFrame);
          return;
        }

        const tPreStart = performance.now();
        const input = await preprocess(tex);
        tex.close();
        const tPreEnd = performance.now();

        const tPredictStart = performance.now();
        const mask = tf.tidy(() => {
          const pred = model.predict(input).squeeze();
          return pred.greater(0.5).toFloat();
        });
        await tf.nextFrame();
        const tPredictEnd = performance.now();

        if (
          maskCanvas.width !== window.innerWidth ||
          maskCanvas.height !== window.innerHeight
        ) {
          maskCanvas.width = window.innerWidth;
          maskCanvas.height = window.innerHeight;
        }

        const tPostStart = performance.now();
        await postprocess(mask);
        const tPostEnd = performance.now();
        tf.dispose([input, mask]);

        const now = performance.now();
        const frameTime = now - lastFrameTime;
        lastFrameTime = now;
        fpsHistory.push(1000 / frameTime);
        if (fpsHistory.length > 30) fpsHistory.shift();
        const avgFps = fpsHistory.reduce((a, b) => a + b, 0) / fpsHistory.length;

        log(
          `Pre: ${(tPreEnd - tPreStart).toFixed(1)}ms\nInfer: ${(tPredictEnd - tPredictStart).toFixed(1)}ms\nPost: ${(tPostEnd - tPredictEnd).toFixed(1)}ms\nFPS: ${avgFps.toFixed(1)}`
        );

        session.requestAnimationFrame(onFrame);
      }

      session.requestAnimationFrame(onFrame);

      document.getElementById('startBtn').style.display = 'none';
    }

    document.getElementById('startBtn').addEventListener('click', () => {
      startAR().catch(e => log('Unexpected error: ' + e.message));
    });
  </script>
</body>
</html>
