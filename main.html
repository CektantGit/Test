<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>AR with WebXR</title>
  <script src="https://unpkg.com/three@0.122.0/build/three.js"></script>
  <script src="https://unpkg.com/three@0.122.0/examples/js/loaders/GLTFLoader.js"></script>
  <script src="https://unpkg.com/three@0.122.0/examples/js/vr/ARButton.js"></script>
  <script src="https://stuk.github.io/jszip/dist/jszip.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script> <!-- TensorFlow.js -->
  <style>
    body { margin: 0; overflow: hidden; }
    canvas { display: block; }
    .overlay { position: absolute; bottom: 10px; right: 10px; z-index: 10; }
    .button { display: block; margin: 5px 0; padding: 10px; background: rgba(0, 0, 0, 0.5); color: white; border: none; border-radius: 5px; cursor: pointer; }
    .info { position: absolute; bottom: 10px; right: 150px; z-index: 10; background: rgba(0, 0, 0, 0.5); color: white; padding: 10px; border-radius: 5px; }
    #startARBtn { position: absolute; top: 10px; left: 10px; z-index: 10; background: rgba(0, 0, 0, 0.7); color: white; padding: 10px; border: none; border-radius: 5px; cursor: pointer; }
  </style>
</head>
<body>
  <button id="startARBtn">Start AR</button>
  <div class="overlay" style="display: none;">
    <button class="button" id="placeFlowerBtn">Place/Move Flower</button>
    <button class="button" id="showInfoBtn">Show Info</button>
  </div>
  <div class="info" id="info">Information will be displayed here.</div>

  <script>
    let flower, reticle, camera, scene, renderer, session, glBinding;
    let model;
    const MODEL_PATH = 'jsModel/model.json'; // Путь к модели

    async function loadModel() {
      model = await tf.loadLayersModel(MODEL_PATH);
    }

    async function activateXR() {
      const canvas = document.createElement('canvas');
      document.body.appendChild(canvas);
      const gl = canvas.getContext('webgl', { xrCompatible: true });

      session = await navigator.xr.requestSession('immersive-ar', { requiredFeatures: ['hit-test', 'dom-overlay', 'camera-access'], domOverlay: { root: document.body } });
      session.updateRenderState({ baseLayer: new XRWebGLLayer(session, gl) });

      glBinding = new XRWebGLBinding(session, gl);

      const referenceSpace = await session.requestReferenceSpace('local');
      const viewerSpace = await session.requestReferenceSpace('viewer');
      const hitTestSource = await session.requestHitTestSource({ space: viewerSpace });

      renderer = new THREE.WebGLRenderer({ canvas: canvas, context: gl, alpha: true });
      renderer.autoClear = false;
      camera = new THREE.PerspectiveCamera();
      camera.matrixAutoUpdate = false;
      scene = new THREE.Scene();

      const directionalLight = new THREE.DirectionalLight(0xffffff, 0.3);
      directionalLight.position.set(10, 15, 10);
      scene.add(directionalLight);

      const loader = new THREE.GLTFLoader();
      loader.load('https://immersive-web.github.io/webxr-samples/media/gltf/reticle/reticle.gltf', (gltf) => {
        reticle = gltf.scene;
        reticle.visible = false;
        scene.add(reticle);
      });

      loader.load('https://immersive-web.github.io/webxr-samples/media/gltf/sunflower/sunflower.gltf', (gltf) => {
        flower = gltf.scene;
      });

      session.requestAnimationFrame(onXRFrame);
    }

    function preprocessImage(image) {
      return tf.tidy(() => {
        let tensor = tf.browser.fromPixels(image);
        tensor = tf.image.resizeBilinear(tensor, [224, 224]);
        tensor = tensor.expandDims(0).toFloat().div(255);
        return tensor;
      });
    }

async function runModel(image) {
  // Преобразование изображения в тензор
  const inputTensor = tf.browser.fromPixels(image)
    .resizeBilinear([224, 224])  // Изменение размера
    .expandDims(0)  // Добавление измерения батча
    .toFloat()
    .div(tf.scalar(255.0));  // Нормализация пикселей
  
  // Выполнение предсказания
  const prediction = await model.predict(inputTensor);
  
  // Возвращаем предсказание
  return prediction;
}

async function postprocess(predictions, width, height) {
  // Умножаем значения предсказания на 255 для видимости
  const scaledPredictions = predictions.mul(tf.scalar(255));

  // Преобразуем предсказание в массив пикселей
  const processedPixels = await scaledPredictions.data(); // Достаём значения из тензора
  
  return processedPixels;
}

async function processFrame(gl, viewCamera) {
  const texture = glBinding.getCameraImage(viewCamera);
  const width = viewCamera.width;
  const height = viewCamera.height;

  const canvas = document.createElement('canvas');
  canvas.width = width;
  canvas.height = height;
  const ctx = canvas.getContext('2d');

  // Рисуем изображение с камеры на канвас
  ctx.drawImage(texture, 0, 0, width, height);

  // Прогоняем изображение через модель (уменьшаем предсказание до 1/4 от оригинала)
  const predictions = await runModel(canvas);

  // Масштабируем предсказания и возвращаем пиксели
  const processedPixels = await postprocess(predictions, width / 4, height / 4);

  // Наложение результата на исходное изображение
  const resultCanvas = document.createElement('canvas');
  resultCanvas.width = width/4;
  resultCanvas.height = height/4;
  const resultCtx = resultCanvas.getContext('2d');

  // Сначала рисуем исходное изображение на результат
  resultCtx.drawImage(texture, 0, 0, width, height);

  // Создаем ImageData из предсказания с меньшими размерами
  const imageData = new ImageData(new Uint8ClampedArray(processedPixels), width / 4, height / 4);

  // Рисуем предсказание в правом верхнем углу
  resultCtx.putImageData(imageData, 0, 0);

  // Отображаем результат
  document.body.appendChild(resultCanvas);
}


    async function onXRFrame(time, frame) {
      const pose = frame.getViewerPose(referenceSpace);
      if (pose) {
        const view = pose.views[0];

        // Обработка кадра
       // await processFrame(gl, view.camera);

        renderer.render(scene, camera);
      }
    }

    async function startAR() {
      await loadModel(); // Загрузка модели
      if (navigator.xr) {
        await activateXR();
      } else {
        alert('WebXR not supported');
      }
    }

    document.getElementById('startARBtn').addEventListener('click', startAR);
  </script>
</body>
</html>
