<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>AR with WebXR</title>
  <script src="https://unpkg.com/three@0.122.0/build/three.js"></script>
  <script src="https://unpkg.com/three@0.122.0/examples/js/loaders/GLTFLoader.js"></script>
  <script src="https://unpkg.com/three@0.122.0/examples/js/vr/ARButton.js"></script>
  <script src="https://stuk.github.io/jszip/dist/jszip.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.7.0/dist/tf.min.js"></script>
  <style>
    body { margin: 0; overflow: hidden; }
    canvas { display: block; }
    .overlay { position: absolute; bottom: 10px; right: 10; z-index: 13; }
    .overlay2 {  display: block;  position: absolute;  top: 0;  left: 0;  width: 100%;  height: 100%;  z-index: 10;}
    .button { display: block; margin: 5px 0; padding: 10px;  z-index: 12; background: rgba(0, 0, 0, 0.5); color: white; border: none; border-radius: 5px; cursor: pointer; }
    .info { position: absolute; bottom: 35px; right: 50px; z-index: 12; background: rgba(0, 0, 0, 0.5); color: white; padding: 10px; border-radius: 5px; }
    #startARBtn { position: absolute; top: 10px; left: 10px; z-index: 12; background: rgba(0, 0, 0, 0.7); color: white; padding: 10px; border: none; border-radius: 5px; cursor: pointer; }
    #captureButton { position: absolute; top: 50px; left: 10px; z-index: 12; background: rgba(0, 0, 0, 0.7); color: white; padding: 10px; border: none; border-radius: 5px; cursor: pointer; }
  </style>
</head>
<body>
  <button id="startARBtn">Start AR</button>
  <button id="captureButton">Capture Image</button>
<div class="overlay">
  <button class="button" id="placeFlowerBtn">Place/Move Flower</button>
  <button class="button" id="showInfoBtn">Show Info</button>
</div>

<div class="overlay2">
  <img id="maskImage"/>
</div>

  
  <div class="info" id="info">Information will be displayed here.</div>

  <script>
    let flower, reticle, camera, scene, renderer, session, glBinding;
    let flowerPlaced = false;
    let captureNext = false;
    const captures = [];
    let model;

    async function loadModel() {
      try {
        model = await tf.loadLayersModel('jsModel/model.json');
        document.getElementById('info').innerText += "\nModel loaded successfully.";
      } catch (error) {
        console.error("Failed to load model", error);
        document.getElementById('info').innerText += "\nFailed to load model: " + error.message;
      }
    }

    async function activateXR() {
      const canvas = document.createElement('canvas');
      document.body.appendChild(canvas);
      const gl = canvas.getContext('webgl', { xrCompatible: true });

      session = await navigator.xr.requestSession('immersive-ar', {
        requiredFeatures: ['hit-test', 'dom-overlay', 'camera-access'],
        domOverlay: { root: document.body }
      });
      session.updateRenderState({ baseLayer: new XRWebGLLayer(session, gl) });

      glBinding = new XRWebGLBinding(session, gl);

      const referenceSpace = await session.requestReferenceSpace('local');
      const viewerSpace = await session.requestReferenceSpace('viewer');
      const hitTestSource = await session.requestHitTestSource({ space: viewerSpace });

      renderer = new THREE.WebGLRenderer({ canvas: canvas, context: gl, alpha: true });
      renderer.autoClear = false;
      camera = new THREE.PerspectiveCamera();
      camera.matrixAutoUpdate = false;
      scene = new THREE.Scene();

      const directionalLight = new THREE.DirectionalLight(0xffffff, 0.3);
      directionalLight.position.set(10, 15, 10);
      scene.add(directionalLight);

      const loader = new THREE.GLTFLoader();
      loader.load('https://immersive-web.github.io/webxr-samples/media/gltf/reticle/reticle.gltf', (gltf) => {
        reticle = gltf.scene;
        reticle.visible = false;
        scene.add(reticle);
      });

      loader.load('https://immersive-web.github.io/webxr-samples/media/gltf/sunflower/sunflower.gltf', (gltf) => {
        flower = gltf.scene;
      });

      const onXRFrame = async (time, frame) => {
        session.requestAnimationFrame(onXRFrame);

        gl.bindFramebuffer(gl.FRAMEBUFFER, session.renderState.baseLayer.framebuffer);

        const pose = frame.getViewerPose(referenceSpace);
        if (pose) {
          
          const view = pose.views[0];

          const viewport = session.renderState.baseLayer.getViewport(view);
          renderer.setSize(viewport.width, viewport.height);

          camera.matrix.fromArray(view.transform.matrix);
          camera.projectionMatrix.fromArray(view.projectionMatrix);
          camera.updateMatrixWorld(true);

          const hitTestResults = frame.getHitTestResults(hitTestSource);
          if (hitTestResults.length > 0 && reticle) {
            const hitPose = hitTestResults[0].getPose(referenceSpace);
            reticle.visible = true;
            reticle.position.set(hitPose.transform.position.x, hitPose.transform.position.y, hitPose.transform.position.z);
            reticle.updateMatrixWorld(true);
          }

          const flowerInScene = scene.children.find(child => child.name === 'sunflower');
          if (flowerInScene) {
            captureImage(gl, glBinding, view.camera);
            if (captureNext && view.camera) {
              captureNext = false;  // Останавливаем захват после кадра
              
            }
          }

          renderer.render(scene, camera);
        }
      };

      session.requestAnimationFrame(onXRFrame);

      document.getElementById('startARBtn').style.display = 'none';
      document.querySelector('.overlay').style.display = 'block';

      document.getElementById('placeFlowerBtn').addEventListener('click', placeFlower);
      document.getElementById('showInfoBtn').addEventListener('click', showInfo);
    }

    async function startAR() {
      if (navigator.xr) {
        await loadModel();  // Загрузка модели перед началом XR-сессии
        await activateXR();
      } else {
        alert('WebXR not supported');
      }
    }

    async function placeFlower() {
      if (!flower) return;

      if (!flowerPlaced) {
        const flowerClone = flower.clone();
        flowerClone.position.copy(reticle.position);
        flowerClone.name = 'sunflower';
        scene.add(flowerClone);
        flowerPlaced = true;
      } else {
        const flowerInScene = scene.children.find(child => child.name === 'sunflower');
        if (flowerInScene) {
          flowerInScene.position.copy(reticle.position);
        }
      }
    }

    function showInfo() {
      if (!flowerPlaced) {
        document.getElementById('info').innerText = 'Flower not placed yet.';
        return;
      }
    }

// Создаем текстуру и фреймбуфер один раз
let copyTexture, framebuffer, program, positionBuffer;

function initializeWebGLResources(gl) {
  // Создаем текстуру
  copyTexture = gl.createTexture();
  gl.bindTexture(gl.TEXTURE_2D, copyTexture);
  gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.LINEAR);
  gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MAG_FILTER, gl.LINEAR);

  // Создаем фреймбуфер
  framebuffer = gl.createFramebuffer();
  gl.bindFramebuffer(gl.FRAMEBUFFER, framebuffer);
  gl.framebufferTexture2D(gl.FRAMEBUFFER, gl.COLOR_ATTACHMENT0, gl.TEXTURE_2D, copyTexture, 0);

  // Компилируем шейдеры и создаем программу
  const vertexShaderSource = `
    attribute vec4 aVertexPosition;
    varying vec2 vTexCoord;
    void main(void) {
      gl_Position = aVertexPosition;
      vTexCoord = (aVertexPosition.xy + 1.0) / 2.0;
    }
  `;

  const fragmentShaderSource = `
    precision mediump float;
    varying vec2 vTexCoord;
    uniform sampler2D uSampler;
    void main(void) {
      gl_FragColor = texture2D(uSampler, vTexCoord);
    }
  `;

  const vertexShader = gl.createShader(gl.VERTEX_SHADER);
  gl.shaderSource(vertexShader, vertexShaderSource);
  gl.compileShader(vertexShader);
  if (!gl.getShaderParameter(vertexShader, gl.COMPILE_STATUS)) {
    console.error('Vertex shader compile error:', gl.getShaderInfoLog(vertexShader));
    document.getElementById('info').innerText += '\nVertex shader compile error: ' + gl.getShaderInfoLog(vertexShader);
  }

  const fragmentShader = gl.createShader(gl.FRAGMENT_SHADER);
  gl.shaderSource(fragmentShader, fragmentShaderSource);
  gl.compileShader(fragmentShader);
  if (!gl.getShaderParameter(fragmentShader, gl.COMPILE_STATUS)) {
    console.error('Fragment shader compile error:', gl.getShaderInfoLog(fragmentShader));
    document.getElementById('info').innerText += '\nFragment shader compile error: ' + gl.getShaderInfoLog(fragmentShader);
  }

  program = gl.createProgram();
  gl.attachShader(program, vertexShader);
  gl.attachShader(program, fragmentShader);
  gl.linkProgram(program);
  if (!gl.getProgramParameter(program, gl.LINK_STATUS)) {
    console.error('Program link error:', gl.getProgramInfoLog(program));
    document.getElementById('info').innerText += '\nProgram link error: ' + gl.getProgramInfoLog(program);
  }

  const vertices = new Float32Array([
    -1.0, -1.0,
    1.0, -1.0,
    -1.0, 1.0,
    1.0, 1.0,
  ]);

  positionBuffer = gl.createBuffer();
  gl.bindBuffer(gl.ARRAY_BUFFER, positionBuffer);
  gl.bufferData(gl.ARRAY_BUFFER, vertices, gl.STATIC_DRAW);
}

// Функция для захвата и обработки изображения
async function captureImage(gl, glBinding, dcamera) {
  const texture = glBinding.getCameraImage(dcamera);
  const width = dcamera.width;
  const height = dcamera.height;
  const scale = 1;
  const scaledWidth = Math.floor(width * scale);
  const scaledHeight = Math.floor(height * scale);
  const textureBytes = scaledWidth * scaledHeight * 4;

  // Переиспользуемый буфер для пикселей
  const readbackPixels = new Uint8Array(textureBytes);

  if (!texture) {
    console.error('Failed to get camera texture');
    document.getElementById('info').innerText += '\nFailed to get camera texture';
    return;
  }

  document.getElementById('info').innerText += '\nTexture acquired. Scaling to ' + scaledWidth + 'x' + scaledHeight;

  gl.bindTexture(gl.TEXTURE_2D, copyTexture);
  gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGBA, scaledWidth, scaledHeight, 0, gl.RGBA, gl.UNSIGNED_BYTE, null);
  
  gl.bindFramebuffer(gl.FRAMEBUFFER, framebuffer);
  gl.framebufferTexture2D(gl.FRAMEBUFFER, gl.COLOR_ATTACHMENT0, gl.TEXTURE_2D, copyTexture, 0);

  if (gl.checkFramebufferStatus(gl.FRAMEBUFFER) !== gl.FRAMEBUFFER_COMPLETE) {
    console.error("Framebuffer incomplete!");
    document.getElementById('info').innerText += '\nFramebuffer incomplete!';
    return;
  }

  document.getElementById('info').innerText += '\nFramebuffer setup complete';

  gl.useProgram(program);
  gl.activeTexture(gl.TEXTURE0);
  gl.bindTexture(gl.TEXTURE_2D, texture);
  gl.uniform1i(gl.getUniformLocation(program, "uSampler"), 0);

  gl.bindBuffer(gl.ARRAY_BUFFER, positionBuffer);
  const position = gl.getAttribLocation(program, "aVertexPosition");
  gl.enableVertexAttribArray(position);
  gl.vertexAttribPointer(position, 2, gl.FLOAT, false, 0, 0);

  gl.viewport(0, 0, scaledWidth, scaledHeight);
  gl.drawArrays(gl.TRIANGLE_STRIP, 0, 4);

  document.getElementById('info').innerText += '\nRendering complete. Reading pixels...';

  gl.readPixels(0, 0, scaledWidth, scaledHeight, gl.RGBA, gl.UNSIGNED_BYTE, readbackPixels);

  // Обработка переворота изображения
  const flippedPixels = new Uint8ClampedArray(readbackPixels);

  for (let y = 0; y < scaledHeight; y++) {
    for (let x = 0; x < scaledWidth; x++) {
      const srcIndex = (y * scaledWidth + x) * 4;
      const destIndex = ((scaledHeight - 1 - y) * scaledWidth + x) * 4;

      flippedPixels[destIndex] = readbackPixels[srcIndex];
      flippedPixels[destIndex + 1] = readbackPixels[srcIndex + 1];
      flippedPixels[destIndex + 2] = readbackPixels[srcIndex + 2];
      flippedPixels[destIndex + 3] = readbackPixels[srcIndex + 3];
    }
  }

  document.getElementById('info').innerText += '\nPixel data flipped. Creating canvas...';

  const canvas = document.createElement('canvas');
  canvas.width = scaledWidth;
  canvas.height = scaledHeight;
  const context = canvas.getContext('2d');
  const imageData = new ImageData(flippedPixels, scaledWidth, scaledHeight);
  context.putImageData(imageData, 0, 0);

  document.getElementById('info').innerText += '\nCanvas created. Converting image for neural network...';

  // Преобразование изображения для нейросети
  const imgTensor = tf.browser.fromPixels(canvas, 3);
  const normalizedImgTensor = imgTensor.div(255.0);
  const resizedImgTensor = tf.image.resizeBilinear(normalizedImgTensor, [224, 224]);
  const batchedImgTensor = resizedImgTensor.expandDims();

  try {
    document.getElementById('info').innerText += '\n' + new Date().toLocaleTimeString('en-GB', { hour12: false }) + ':' + new Date().getMilliseconds();
    const predictions = await model.predict(batchedImgTensor);
    document.getElementById('info').innerText += '\n' + new Date().toLocaleTimeString('en-GB', { hour12: false }) + ':' + new Date().getMilliseconds();

    console.log("Model predictions:", predictions);

    const unetMask = predictions;
    const unetMaskArray = unetMask.dataSync();
    const maskCanvas = document.createElement('canvas');
    maskCanvas.width = 224;
    maskCanvas.height = 224;
    const maskCtx = maskCanvas.getContext('2d');
    const maskImageData = maskCtx.createImageData(224, 224);

    for (let i = 0; i < 224 * 224; i++) {
      const value = unetMaskArray[i] * 255;
      maskImageData.data[i * 4] = value;
      maskImageData.data[i * 4 + 1] = value;
      maskImageData.data[i * 4 + 2] = value;
      maskImageData.data[i * 4 + 3] = 255;
    }

    maskCtx.putImageData(maskImageData, 0, 0);
    document.getElementById('info').innerText += '\nPrediction processed. Displaying mask...';

    const maskImageElement = document.getElementById('maskImage');
    maskImageElement.src = maskCanvas.toDataURL('image/png');
    document.querySelector('.overlay').style.display = 'block';

  } catch (error) {
    console.error('Error during model prediction:', error);
    document.getElementById('info').innerText += "\nError during model prediction: " + error.message;
  }
}



    document.getElementById('startARBtn').addEventListener('click', startAR);
    document.getElementById('captureButton').addEventListener('click', () => captureNext = true);
  </script>
</body>
</html>
