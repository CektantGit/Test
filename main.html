<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>AR with WebXR</title>
  <script src="https://unpkg.com/three@0.122.0/build/three.js"></script>
  <script src="https://unpkg.com/three@0.122.0/examples/js/loaders/GLTFLoader.js"></script>
  <script src="https://unpkg.com/three@0.122.0/examples/js/vr/ARButton.js"></script>
  <script src="https://stuk.github.io/jszip/dist/jszip.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.7.0/dist/tf.min.js"></script>
  <style>
    body { margin: 0; overflow: hidden; }
    canvas { display: block; }
    .overlay { position: absolute; bottom: 10px; right: 10px; z-index: 10; }
    .button { display: block; margin: 5px 0; padding: 10px; background: rgba(0, 0, 0, 0.5); color: white; border: none; border-radius: 5px; cursor: pointer; }
    .info { position: absolute; bottom: 10px; right: 150px; z-index: 10; background: rgba(0, 0, 0, 0.5); color: white; padding: 10px; border-radius: 5px; }
    #startARBtn { position: absolute; top: 10px; left: 10px; z-index: 10; background: rgba(0, 0, 0, 0.7); color: white; padding: 10px; border: none; border-radius: 5px; cursor: pointer; }
    #captureButton { position: absolute; top: 50px; left: 10px; z-index: 10; background: rgba(0, 0, 0, 0.7); color: white; padding: 10px; border: none; border-radius: 5px; cursor: pointer; }
  </style>
</head>
<body>
  <button id="startARBtn">Start AR</button>
  <button id="captureButton">Capture Image</button>
  <div class="overlay" style="display: none;">
    <button class="button" id="placeFlowerBtn">Place/Move Flower</button>
    <button class="button" id="showInfoBtn">Show Info</button>
  </div>
  <div class="info" id="info">Information will be displayed here.</div>

  <script>
    let flower, reticle, camera, scene, renderer, session, glBinding;
    let flowerPlaced = false;
    let captureNext = false;
    const captures = [];
    let model;
    const TARGET_SIZE = 224; // Размер для изменения разрешения

    function logInfo(message) {
      const infoElement = document.getElementById('info');
      infoElement.innerText += `\n${message}`;
      console.log(message);
    }

    async function loadModel() {
      try {
        logInfo('Loading model...');
        model = await tf.loadLayersModel('jsModel/model.json');
        logInfo('Model loaded successfully.');
      } catch (error) {
        logInfo('Failed to load model: ' + error.message);
      }
    }

    async function activateXR() {
      try {
        logInfo('Activating XR...');
        const canvas = document.createElement('canvas');
        document.body.appendChild(canvas);
        const gl = canvas.getContext('webgl', { xrCompatible: true });

        session = await navigator.xr.requestSession('immersive-ar', {
          requiredFeatures: ['hit-test', 'dom-overlay', 'camera-access'],
          domOverlay: { root: document.body }
        });
        session.updateRenderState({ baseLayer: new XRWebGLLayer(session, gl) });

        glBinding = new XRWebGLBinding(session, gl);

        const referenceSpace = await session.requestReferenceSpace('local');
        const viewerSpace = await session.requestReferenceSpace('viewer');
        const hitTestSource = await session.requestHitTestSource({ space: viewerSpace });

        renderer = new THREE.WebGLRenderer({ canvas: canvas, context: gl, alpha: true });
        renderer.autoClear = false;
        camera = new THREE.PerspectiveCamera();
        camera.matrixAutoUpdate = false;
        scene = new THREE.Scene();

        const directionalLight = new THREE.DirectionalLight(0xffffff, 0.3);
        directionalLight.position.set(10, 15, 10);
        scene.add(directionalLight);

        const loader = new THREE.GLTFLoader();
        loader.load('https://immersive-web.github.io/webxr-samples/media/gltf/reticle/reticle.gltf', (gltf) => {
          reticle = gltf.scene;
          reticle.visible = false;
          scene.add(reticle);
          logInfo('Reticle model loaded.');
        }, undefined, (error) => {
          logInfo('Error loading reticle model: ' + error.message);
        });

        loader.load('https://immersive-web.github.io/webxr-samples/media/gltf/sunflower/sunflower.gltf', (gltf) => {
          flower = gltf.scene;
          logInfo('Flower model loaded.');
        }, undefined, (error) => {
          logInfo('Error loading flower model: ' + error.message);
        });

        const onXRFrame = async (time, frame) => {
          session.requestAnimationFrame(onXRFrame);

          gl.bindFramebuffer(gl.FRAMEBUFFER, session.renderState.baseLayer.framebuffer);

          const pose = frame.getViewerPose(referenceSpace);
          if (pose) {
            const view = pose.views[0];

            const viewport = session.renderState.baseLayer.getViewport(view);
            renderer.setSize(viewport.width, viewport.height);

            camera.matrix.fromArray(view.transform.matrix);
            camera.projectionMatrix.fromArray(view.projectionMatrix);
            camera.updateMatrixWorld(true);

            const hitTestResults = frame.getHitTestResults(hitTestSource);
            if (hitTestResults.length > 0 && reticle) {
              const hitPose = hitTestResults[0].getPose(referenceSpace);
              reticle.visible = true;
              reticle.position.set(hitPose.transform.position.x, hitPose.transform.position.y, hitPose.transform.position.z);
              reticle.updateMatrixWorld(true);
            }

            const flowerInScene = scene.children.find(child => child.name === 'sunflower');
            if (flowerInScene) {
              if (captureNext && view.camera) {
                captureNext = false;
                await captureImage(gl, glBinding, view.camera);
              }
            }

            renderer.render(scene, camera);
          }
        };

        session.requestAnimationFrame(onXRFrame);

        document.getElementById('startARBtn').style.display = 'none';
        document.querySelector('.overlay').style.display = 'block';

        document.getElementById('placeFlowerBtn').addEventListener('click', placeFlower);
        document.getElementById('showInfoBtn').addEventListener('click', showInfo);
      } catch (error) {
        logInfo('Error activating XR: ' + error.message);
      }
    }

    async function startAR() {
      if (navigator.xr) {
        await loadModel();
        await activateXR();
      } else {
        logInfo('WebXR not supported');
      }
    }

    async function placeFlower() {
      if (!flower) {
        logInfo('Flower model not loaded yet.');
        return;
      }

      if (!flowerPlaced) {
        const flowerClone = flower.clone();
        flowerClone.position.copy(reticle.position);
        flowerClone.name = 'sunflower';
        scene.add(flowerClone);
        flowerPlaced = true;
        logInfo('Flower placed in scene.');
      } else {
        const flowerInScene = scene.children.find(child => child.name === 'sunflower');
        if (flowerInScene) {
          flowerInScene.position.copy(reticle.position);
          logInfo('Flower moved to new position.');
        } else {
          logInfo('Flower not found in scene.');
        }
      }
    }

    function showInfo() {
      if (!flowerPlaced) {
        logInfo('Flower not placed yet.');
      }
    }

    async function captureImage(gl, glBinding, dcamera) {
      try {
        logInfo('Capturing image...');

        const texture = glBinding.getCameraImage(dcamera);
        if (!texture) {
          logInfo('Failed to get camera texture');
          return;
        }

        const width = dcamera.width;
        const height = dcamera.height;

        const scale = 1;
        const scaledWidth = Math.floor(width * scale);
        const scaledHeight = Math.floor(height * scale);

        let readbackPixels = new Uint8Array(scaledWidth * scaledHeight * 4);

        let copyTexture = gl.createTexture();
        gl.bindTexture(gl.TEXTURE_2D, copyTexture);
        gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGBA, scaledWidth, scaledHeight, 0, gl.RGBA, gl.UNSIGNED_BYTE, null);
        gl.bindTexture(gl.TEXTURE_2D, null);

        let framebuffer = gl.createFramebuffer();
        gl.bindFramebuffer(gl.FRAMEBUFFER, framebuffer);
        gl.framebufferTexture2D(gl.FRAMEBUFFER, gl.COLOR_ATTACHMENT0, gl.TEXTURE_2D, copyTexture, 0);

        if (gl.checkFramebufferStatus(gl.FRAMEBUFFER) !== gl.FRAMEBUFFER_COMPLETE) {
          logInfo('Framebuffer incomplete!');
          return;
        }

        const vertexShaderSource = `
          attribute vec4 aVertexPosition;
          varying vec2 vTexCoord;
          void main(void) {
            gl_Position = aVertexPosition;
            vTexCoord = (aVertexPosition.xy + 1.0) / 2.0;
          }
        `;
        const fragmentShaderSource = `
          precision mediump float;
          varying vec2 vTexCoord;
          uniform sampler2D uSampler;
          void main(void) {
            gl_FragColor = texture2D(uSampler, vTexCoord);
          }
        `;

        const vertexShader = gl.createShader(gl.VERTEX_SHADER);
        gl.shaderSource(vertexShader, vertexShaderSource);
        gl.compileShader(vertexShader);
        if (!gl.getShaderParameter(vertexShader, gl.COMPILE_STATUS)) {
          logInfo('Error compiling vertex shader: ' + gl.getShaderInfoLog(vertexShader));
          gl.deleteShader(vertexShader);
          return;
        }

        const fragmentShader = gl.createShader(gl.FRAGMENT_SHADER);
        gl.shaderSource(fragmentShader, fragmentShaderSource);
        gl.compileShader(fragmentShader);
        if (!gl.getShaderParameter(fragmentShader, gl.COMPILE_STATUS)) {
          logInfo('Error compiling fragment shader: ' + gl.getShaderInfoLog(fragmentShader));
          gl.deleteShader(fragmentShader);
          return;
        }

        const program = gl.createProgram();
        gl.attachShader(program, vertexShader);
        gl.attachShader(program, fragmentShader);
        gl.linkProgram(program);
        if (!gl.getProgramParameter(program, gl.LINK_STATUS)) {
          logInfo('Error linking program: ' + gl.getProgramInfoLog(program));
          return;
        }

        gl.useProgram(program);
        gl.activeTexture(gl.TEXTURE0);
        gl.bindTexture(gl.TEXTURE_2D, texture);
        gl.uniform1i(gl.getUniformLocation(program, 'uSampler'), 0);

        const vertices = new Float32Array([
          -1.0, -1.0,
           1.0, -1.0,
          -1.0,  1.0,
           1.0,  1.0,
        ]);
        const positionBuffer = gl.createBuffer();
        gl.bindBuffer(gl.ARRAY_BUFFER, positionBuffer);
        gl.bufferData(gl.ARRAY_BUFFER, vertices, gl.STATIC_DRAW);
        const position = gl.getAttribLocation(program, 'aVertexPosition');
        gl.enableVertexAttribArray(position);
        gl.vertexAttribPointer(position, 2, gl.FLOAT, false, 0, 0);

        gl.viewport(0, 0, scaledWidth, scaledHeight);
        gl.drawArrays(gl.TRIANGLE_STRIP, 0, 4);

        gl.readPixels(0, 0, scaledWidth, scaledHeight, gl.RGBA, gl.UNSIGNED_BYTE, readbackPixels);

        logInfo('Image captured from WebGL.');

        const canvas = document.createElement('canvas');
        canvas.width = scaledWidth;
        canvas.height = scaledHeight;
        const context = canvas.getContext('2d');
        const imageData = new ImageData(new Uint8ClampedArray(readbackPixels), scaledWidth, scaledHeight);
        context.putImageData(imageData, 0, 0);

        const resizedCanvas = document.createElement('canvas');
        resizedCanvas.width = TARGET_SIZE;
        resizedCanvas.height = TARGET_SIZE;
        const resizedContext = resizedCanvas.getContext('2d');
        resizedContext.drawImage(canvas, 0, 0, TARGET_SIZE, TARGET_SIZE);

        try {
          logInfo('Preparing image for model prediction.');
          const inputImage = tf.browser.fromPixels(resizedCanvas).toFloat().expandDims(0);
          const prediction = await model.predict(inputImage).squeeze().array();
          logInfo('Prediction completed.');

          const outputCanvas = document.createElement('canvas');
          outputCanvas.width = TARGET_SIZE;
          outputCanvas.height = TARGET_SIZE;
          const outputContext = outputCanvas.getContext('2d');
          const predictionData = new Float32Array(prediction[0]);

          if (predictionData.length === TARGET_SIZE * TARGET_SIZE) {
            const outputImageData = new ImageData(new Uint8ClampedArray(predictionData), TARGET_SIZE, TARGET_SIZE);
            outputContext.putImageData(outputImageData, 0, 0);

            const dataURL = outputCanvas.toDataURL();
            const a = document.createElement('a');
            a.href = dataURL;
            a.download = 'prediction.png';
            a.click();
            logInfo('Prediction image saved as prediction.png.');
          } else {
            logInfo('Prediction data length does not match expected size.');
          }

        } catch (error) {
          logInfo('Error during model prediction: ' + error.message);
        } finally {
          gl.bindFramebuffer(gl.FRAMEBUFFER, null);
          gl.deleteFramebuffer(framebuffer);
          gl.deleteTexture(copyTexture);
          gl.deleteProgram(program);
          gl.deleteShader(vertexShader);
          gl.deleteShader(fragmentShader);
          gl.deleteBuffer(positionBuffer);
          logInfo('Cleaned up resources after image capture.');
        }
      } catch (error) {
        logInfo('Error during image capture: ' + error.message);
      }
    }

    document.getElementById('startARBtn').addEventListener('click', startAR);
    document.getElementById('captureButton').addEventListener('click', () => {
      captureNext = true;
    });
  </script>
</body>
</html>
